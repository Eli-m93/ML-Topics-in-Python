{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Basics of an RCT (A/B test)__:\n",
    "\n",
    "\n",
    "## This notebook has 3 sections:\n",
    "1. [Example of an RCT](#Example_RCT)\n",
    "2. [Covid-19 RCT: Calculating Variance via Bootstrap (Q2)](#covid_rct)\n",
    "3. [Work Program RCT: Conditional Average Treatment Effects (Q3)](#work_rct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of any inference questions across industry or policy is if certain actions *cause* change across their population. Simple analysis over a sample might provide useful information on *predicting* or *finding significant changes* across groups but seldom provides a causal interpretation.\n",
    "\n",
    "<a id='Example_RCT'></a>\n",
    "## Example: loyalty Program\n",
    "\n",
    "As an example imagine you're a researcher for a retail company. You're task with learning how their new loyalty card affects sales. As any good researcher you take in your data of customers: \n",
    "$$\n",
    "Y_i = \\alpha D_i + \\beta + \\epsilon_i\n",
    "$$ \n",
    "where $Y_i$ is customer $i$'s spending amount in dollars, $D_i$ indicates if the customer is a loyalty card holder, and $\\beta$ is the intercept term. If $D_i=1$, then individual $i$ has a loyalty card and we can say $Y(D=1) = Y(1) = \\alpha+\\beta+\\epsilon_i$. If $D=0$, then individual $i$ has no loyalty card and we can say $Y(D=0) = Y(0) = \\beta+\\epsilon_i$\n",
    "\n",
    "\n",
    "__With this model in mind you find $\\hat{\\alpha}$ = $\\$25$ and is statisically significant.__ \n",
    "### What can this analysis tell us?:\n",
    "\n",
    "1. loyalty card holders spend more than non card holders.\n",
    "2. We could predict high spending customers by knowing if they have a loyalty card.\n",
    "\n",
    "\n",
    "### What can this analysis *not* tell us?:\n",
    "While the example above could provide helpful predictive insights, we __cannot__ say that this loyalty card is the reason why customers spend more in stores, why is this? To better understand lets turn to our model again:\n",
    "\n",
    "For us to assume that what we're studying *causes* an outcome, then in $Y_i = \\alpha D_i + \\beta + \\epsilon_i$ we need to believe that:\n",
    " $$\n",
    " ED_i\\epsilon_i = 0\n",
    " $$ \n",
    " meaning that on average, customer $i$'s willingness to have a loyalty card ($D_i$) is unrelated to their unobserved charaterisics on spending ($\\epsilon_i$). However just analyzing data after the fact does little in the way of telling us if pushing a loyalty card over other actions is the best way to increase sales. \n",
    "\n",
    "Here are two (potential) reasons why $ED_i\\epsilon_i \\not= 0$:\n",
    "1. loyalty card holders high higher incomes, so $\\epsilon_i = \\beta_1 Income + U_i$ and it's the correlation of income & loyalty cards that give us our result, i.e. $ED_i\\epsilon_i > 0$\n",
    "2. loyalty cards actually lower total sales, but the loyalty program was pushed heavily in stores around resorts where sales are higher than the majority of shops. \n",
    "\n",
    "Both example serve as cases of omitted variable bias in different directions. \n",
    "\n",
    "--------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Benefit of RCT's:\n",
    "\n",
    "Hopefully the example above helps illucidate the fact that while predictive and causal analysis might use the same tools, the insights and methods can vary widely and while simple analysis might be able to inform both quesitons it mostly cannot. This is where an RCT can help bolster causal inference.\n",
    "\n",
    "In short an RCT aims to alleviate bias in our model by randomally allocating indiviuals in the population (or sample) to treatment ($D=1$) or control ($D=0$). This results in in $ED_i\\epsilon_i = 0$, so entry into the treatment group is seemingly random. How to balance our population and conduct an RCT is a field of study within itself as bias can still seep in pre-analysis, during analysis, or post-analysis. In short some considerations could be:\n",
    "\n",
    "### Considerations:\n",
    "\n",
    "1. At what level do I randomize? At the city, town, store, hospital, website, classroom, house, etc...?\n",
    "2. On what covariates/charaterisics do I balance on? Could there unobserved bias I am not picking up?\n",
    "3. What spillover could occur between our treatment and control groups? How would this bias my endline results?\n",
    "4. Why is there attrition, is this random or not? Why are they leaving my study?\n",
    "\n",
    "\n",
    "### Loyality Program as RCT\n",
    "\n",
    "Lets return to our loyality program example, now lets assume that the company gives you the freedom to set up an experiment in a new city. Here you have the freedom to randomally split customers into the loyality card group ($D=1$) or the no card group ($D=0$). For the sake of simplicity you manage to have a truly random split for your treatment and control group so that the any charateristic you can imagine (we can all a vector of characteristics/covariates as $X$) are equal across groups ($EX(D=1) = EX(D=0)$. Now you rerun your analysis and find $\\hat{\\alpha}$ to equal 5\\$ and is statisically significant! Lets break this down:\n",
    "\n",
    "What we found was that: $Y(D=1) - Y(D=0) = 5\\$$, or that our __treatment effect__ (which we denote with $\\delta$) equals 5 dollars. Therefore, providing a customer with a loyality card increases sales by five dollars over a customer without one!\n",
    "\n",
    "-------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='covid_rct'></a>\n",
    "# Working with RCT Data: Covid-19 Vaccine\n",
    "\n",
    "### Q: Study the notebook on vaccinations RCTs. Try to replicate the results in the FDA briefing table for each age 18-64 (exact replication is not required). Explain your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I try to replicate findings from an FDA briefing on Pfizer's Covid-19 vaccine efficacy. The [CDC](https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section6.html) defines vaccine efficacy:\n",
    "$$\n",
    "\\operatorname{VE} = \\frac{\\text{Risk for Unvaccianted - Risk for Vaccinated}}{\\text{Risk for Unvaccianted}}.\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This table provides endline results: \n",
    "\n",
    "\n",
    "![](https://lh6.googleusercontent.com/oiO6gYom1UZyrOhgpFx2iq8ike979u3805JHiVygP-Efh1Yaz2ttyPcgWKlT1AqHDM4v46th3EPIkOvRLyXA0fNUloPL-mL9eOFmSAzfbNOHyCZSQ0DyzMhcFUtQuZ520R5Qd2lj):\n",
    "\n",
    "\n",
    "For this replication I will focus on the __18 to 64__ range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NV = 14443 #Number vaccinated in 18 to 64 group\n",
    "NU = 14566 #number unvaccinated \n",
    "RV = 8/NV #risk of covid for vaccinated \n",
    "RU = 149/NU #risk of covid for unvaccinated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating vaccine efficiency (VE) is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vaccine Efficiency (VE)\n",
    "VE = round((RU-RV)/RU, 3)\n",
    "\n",
    "print(f\"The Pfizer Covid-19 Vaccine is {VE} for individuals between the ages of 16 to 64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge is to calculate approximate variance estimates to figure out the confidence interval around vaccine efficiacy. This is challenging because we're not interested in the variance of $V[Covid|Vax=1]$ or $V[Covid|Vax=0]$, but instead some combination of both variances. Luckily we can use bootstrapping to find the variance of vaccine efficacy.\n",
    "\n",
    "Bootstrapping in this context requires us to calculate the variance of each outcome (risk for vax'd & unxav'd) by slightly perturbing each iteration by a random value taken from a normal distribution of each outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find variance of RU & RV, as they're bernoulli in a sample its just (p)(p-1) divided by our sample size\n",
    "\n",
    "var_RV = RV*(1-RV)/NV\n",
    "var_RU = RU*(1-RU)/NU\n",
    "\n",
    "#Now to bootstrap we must specify how many iterations we want, lets do 10,000\n",
    "B=10000\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "\n",
    "RV_bs_var = RV + np.random.normal(0,1,B)*(var_RV)**0.5\n",
    "RU_bs_var = RU + np.random.normal(0,1,B)*(var_RU)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEs= (RU_bs_var - RV_bs_var)/RU_bs_var\n",
    "CI_VE_L = np.quantile(VEs, .025)\n",
    "CI_VE_U = np.quantile(VEs, .975)\n",
    "print(\"95 % confidence interval is [\" + str(round(CI_VE_L, 3)), \",\", str(round(CI_VE_U, 3)),\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.Series(VEs).to_frame('Data')\n",
    "sns.set(style='darkgrid')\n",
    "sns.kdeplot(data=df,\n",
    "            x='Data',\n",
    "            bw_method = 0.2,\n",
    "            color = 'olive',\n",
    "            shade=True)\n",
    "plt.xlabel(\"Vaccine Efficiency (%)\")\n",
    "plt.ylabel(\"\");\n",
    "plt.title(\"Vaccine Efficiency Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='work_rct'></a>\n",
    "# Working with RCT Data: Pennsylvania Reemployment Bonus Experiment (Analysis ongoing, explanation available)\n",
    "\n",
    "### Q: Study the notebook on the Reemployment example; experiment with putting even more flexible controls (e.g. use interactions of all controls); report your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Average Treatment Effects\n",
    "In a successful RCT we ensure that the treatment group (denoted as $D$=1) ought to be no different than the control group ($D$=0). This ensures that the average treatment effect is causal & non-biased. Put more formally:\n",
    "\n",
    "$$\n",
    "E[X|D=1] = E[X|D=0] \n",
    "$$\n",
    "\n",
    "Where $X$ is a vector of controls.\n",
    "\n",
    "With this condition achieved we are able to not only understand our average treatment effect but can reveal any heterogenous effects across different levels of $X$, we call this __Conditional Average Treatment Effects (CATE).__\n",
    "\n",
    "While the canonical RCT model might look like this:\n",
    "$$\n",
    "Y_i = \\alpha D_i + \\beta_0 + \\beta 'X_i + \\epsilon_i \n",
    "$$\n",
    "\n",
    "Where the coefficient $\\alpha$ is the ATE from treatment.\n",
    "\n",
    "Now we can *interact* our controls by treatment to study our CATE:\n",
    "$$\n",
    "Y_i = \\alpha 'X_iD_i + \\beta_0 + \\beta 'X + \\epsilon_i \n",
    "$$\n",
    "\n",
    "Now we have many $\\alpha$ coeifficents, where $\\alpha_1$ corresponds to the ATE and $\\alpha_2$ to $\\alpha_k$ correspond to additive effects based on our $k$ number of controls. For instance, in our loyality card example imagine $X_k$ is an indicator for male, it could be the case that $\\alpha_1 + \\alpha_k > \\alpha_1$, meaning loyality cards increase sales for everyone but even more so for men.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing Precision & Accuracy in RCTS: Controlling for Covariates\n",
    "\n",
    "Even if heterogenous effects are of no interest to the study we can still add our available covariates/controls to increase precision of our estimates, precision being the improving standard errors to better detect statistical significance. \n",
    "\n",
    "Why is this? Let's imagine you run an RCT and randomize, we would expect the treatment effect (denoted as $\\alpha$) to be unbiased between our treatment and control, this is because any characteristics between the two groups are the same, therefore:\n",
    "\n",
    "$$\n",
    "EY(1) - EY(0) = \\alpha + \\beta(\\bar{X}_{treat} - \\bar{X}_{control}) + (\\bar{\\epsilon}_{treat} - \\bar{\\epsilon}_{control})\n",
    "$$\n",
    "\n",
    "I.E. the treatment effect equals alpha if we randomize perfectly (difference in X's net to 0) and the expected unobserved differences between groups (denoted with the error terms) net to zero. However RCTs don't always run without a hitch, therefore controlling for characterizes ex-post can attenuate any bias by ensuring differences between groups net to zero. \n",
    "\n",
    "Even if we balance treatment & control perfectly including covariates that are predictive of our outcome can reduce noise and lower the standard error of our ATE variable, this is generally true if the covariates explain Y in anyway. If we can explain Y in a better sense, we then can reduce noise in Y, meaning the noise in ATE will lower in part.\n",
    "\n",
    "below is an easy example to show this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+-----------+----------------+\n",
      "|               Model Type              | Beta Coef | Standard Error |\n",
      "+---------------------------------------+-----------+----------------+\n",
      "|  Treatment (z) w/o Control (x1) added |  -0.14237 |    0.18273     |\n",
      "| Treatment (z) WITH Control (x1) added |  -0.14237 |    0.18361     |\n",
      "+---------------------------------------+-----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "#Make a dataframe of z = Treatment Group\n",
    "# x_var = control\n",
    "# make it so that individuals in treatment (z=1) are no different to individuals in control (z = 0).\n",
    "df = pd.DataFrame(columns=['y', 'x1', 'z'])\n",
    "\n",
    "for z_var in [0, 1]:\n",
    "    for x_var in [0,1]:\n",
    "        sample = pd.DataFrame({'y': np.random.randn(25),\n",
    "                           'x1': x_var,\n",
    "                           'z': z_var},\n",
    "                          index = np.arange(0,25))\n",
    "        \n",
    "        df = df.append(sample)\n",
    "        \n",
    "        \n",
    "        \n",
    "result_no_x = sm.ols(formula=\"y ~ z\", data=df).fit()\n",
    "result_w_x = sm.ols(formula=\"y ~ z+x1\", data=df).fit()\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [\"Model Type\", \"Beta Coef\", \"Standard Error\"]\n",
    "pt.add_row([\"Treatment (z) w/o Control (x1) added\", round(result_no_x.params[1],5), round(result_no_x.bse[1],5)])\n",
    "pt.add_row([\"Treatment (z) WITH Control (x1) added\", round(result_w_x.params[1],5), round(result_w_x.bse[1],5)])\n",
    "print(pt)\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3472633a0c3319afea4dee893cd914becdcc9b59b8cbd89385fb4e7aafbcbb11"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
